# Data dirs

data_train: 'datasets/CelebAHQ/data256x256/train/'
data_test: 'datasets/CelebAHQ/data256x256/test/'
mask_train: 'datasets/Nvidia-masks/train_mask_dataset/'
mask_test: 'datasets/Nvidia-masks/test_mask_dataset/'

# Model setting

model_name: 'RaGAN'

# Training settings

im_size: [3, 256, 256]
workers: 24
batch_size: 18
epochs: 100
start_epoch: 0
gpu_id: 0
learning_rate_D: 0.0002
learning_rate_G: 0.0002
adam_betas_D: [0.5, 0.9]
adam_betas_G: [0.5, 0.9]
checkpoint_interval: 1
sample_interval: 100
warmup_batches: 1500
debug: False
freeze_epoch: None
resume: 'checkpoints_RaGAN/checkpoints_model_2_bce/checkpoint.pth.tar'
parallel: False
# adversarial mode: bce or l1
adv_mode: 'bce'
train_interval_D: 2

# Loss coefecients

l1_coef: 1 #
guided_coef: 25
fm_vgg_coef: 25
fm_dis_coef: 5 #
adv_G_coef: 0.03 #
adv_D_coef: 1
align_coef: 1

# Logging

checkpoint_dir: 'checkpoints_RaGAN/checkpoints_model_2_bce'
eval_dir: 'eval_epochs/model_2_bce'
logger: 'logger.txt'
logdir: 'runs'
writer_name: 'runs/model_2_bce'


# Dataset
# options: 'celeba-hq'
dataset: 'celeba-hq'
#options: 'nvidia'
mask_dataset: 'nvidia'




















